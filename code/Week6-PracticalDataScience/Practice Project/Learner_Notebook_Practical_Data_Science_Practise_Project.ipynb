{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dense-medicaid"
   },
   "source": [
    "# **Classification Project - Hotel Booking Cancellation Prediction**\n",
    "\n",
    "\n",
    "Welcome to the project on classification. We will use the **INN Hotels dataset** for this project.\n",
    "\n",
    "--------------------------------\n",
    "## **Context** \n",
    "-------------------------------\n",
    "\n",
    "A significant number of hotel bookings are called off due to cancellations or no-shows. The typical reasons for cancellations include changes of plans, scheduling conflicts, etc. This is often made easier by the option to do so free of charge or preferably at a low cost which is beneficial to hotel guests but it is a less desirable and possibly revenue-diminishing factor for hotels to deal with. Such losses are particularly high on last-minute cancellations.\n",
    "\n",
    "The new technologies involving online booking channels have dramatically changed customers' booking possibilities and behavior. This adds a further dimension to the challenge of how hotels handle cancellations, which are no longer limited to traditional booking and guest characteristics.\n",
    "\n",
    "The cancellation of bookings potentially impacts a hotel on various fronts:\n",
    "1. Loss of resources (revenue) when the hotel cannot resell the room.\n",
    "2. Additional costs of distribution channels by increasing commissions or paying for publicity to help sell these rooms.\n",
    "3. Lowering prices at last minute, so the hotel can resell a room, resulting in reducing the profit margin.\n",
    "4. Human resources to make arrangements for the guests.\n",
    "\n",
    "----------------------------\n",
    "## **Objective**\n",
    "----------------------------- \n",
    "\n",
    "The increasing number of cancellations calls for a Machine Learning based solution that can help in predicting **which booking is likely to be canceled**. INN Hotels Group has a chain of hotels in Portugal, they are facing problems with the high number of booking cancellations and have reached out to your firm for data-driven solutions. You, as a data scientist, have to analyze the data provided to find which **factors have a high influence on booking cancellations, build a predictive model that can predict which booking is going to be canceled in advance, and help in formulating profitable policies for cancellations and refunds.**\n",
    "\n",
    "\n",
    "--------------------------\n",
    "## **Data Description**\n",
    "--------------------------\n",
    "\n",
    "The data contains the different attributes of customers' booking details. The detailed data dictionary is given below.\n",
    "\n",
    "\n",
    "**Data Dictionary**\n",
    "\n",
    "* Booking_ID: The unique identifier of each booking\n",
    "\n",
    "* no_of_adults: The number of adults\n",
    "\n",
    "* no_of_children: The number of children\n",
    "\n",
    "* no_of_weekend_nights: The number of weekend nights (Saturday and Sunday) the guest stayed or booked to stay at the hotel\n",
    "\n",
    "* no_of_week_nights: The number of weeknights (Monday to Friday) the guest stayed or booked to stay at the hotel\n",
    "\n",
    "* type_of_meal_plan: The type of meal plan booked by the customer:\n",
    "    * Not Selected – No meal plan selected\n",
    "    * Meal Plan 1 – Breakfast\n",
    "    * Meal Plan 2 – Half board (breakfast and one other meal)\n",
    "    * Meal Plan 3 – Full board (breakfast, lunch, and dinner)\n",
    "\n",
    "* required_car_parking_space: Does the customer require a car parking space? (0 - No, 1- Yes)\n",
    "\n",
    "* room_type_reserved: The type of room reserved by the customer. The values are ciphered (encoded) by INN Hotels.\n",
    "\n",
    "* lead_time: The number of days between the date of booking and the arrival date\n",
    "\n",
    "* arrival_year: The year of arrival date\n",
    "\n",
    "* arrival_month: The month of arrival date\n",
    "\n",
    "* arrival_date: The date of the month\n",
    "\n",
    "* market_segment_type: Market segment designation.\n",
    "\n",
    "* repeated_guest: Is the customer a repeated guest? (0 - No, 1- Yes)\n",
    "\n",
    "* no_of_previous_cancellations: The number of previous bookings that were canceled by the customer before the current booking\n",
    "\n",
    "* no_of_previous_bookings_not_canceled: The number of previous bookings not canceled by the customer before the current booking\n",
    "\n",
    "* avg_price_per_room: The average price per day for the reservation; prices of the rooms are dynamic. (in euros)\n",
    "\n",
    "* no_of_special_requests: The total number of special requests made by the customer (e.g. high floor, view from the room, etc.)\n",
    "\n",
    "* booking_status: Flag indicating if the booking was canceled or not. The class 0 represents the Not_Canceled whereas class 1 represents the Canceled label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_H95w_NB5gi"
   },
   "source": [
    "## **Importing the necessary libraries and overview of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwwF_pNwB5gj"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Libraries for data manipulation and visualization\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Algorithms to use\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Metrics to evaluate the model\n",
    "from sklearn.metrics import confusion_matrix, classification_report,f1_score\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# For hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fantastic-rebel"
   },
   "source": [
    "### **Loading the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "precious-leonard"
   },
   "outputs": [],
   "source": [
    "hotel = pd.read_csv(\"INNHotelsGroup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geographic-gender"
   },
   "outputs": [],
   "source": [
    "# Copying data to another variable to avoid any changes to original data\n",
    "data = hotel.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "convinced-blackberry"
   },
   "source": [
    "### **View the first and the last 5 rows of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tested-adjustment",
    "outputId": "5a49f79c-b530-49ec-aee1-b540342ffa6a"
   },
   "outputs": [],
   "source": [
    "# View head of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "demonstrated-charger",
    "outputId": "0771f554-108a-4473-c622-8135ad412e3f"
   },
   "outputs": [],
   "source": [
    "# View tail of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "creative-warner"
   },
   "source": [
    "### **Checking the info of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "expanded-technique",
    "outputId": "a96250c8-79f8-4a28-d671-5849b398180a"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "august-hopkins"
   },
   "source": [
    "* The dataset has **36,275 rows and 19 columns**. \n",
    "\n",
    "* `Booking_ID`, `type_of_meal_plan`, `room_type_reserved`, `market_segment_type`, and `booking_status` are of **object type** while the rest of the columns are numeric in nature.\n",
    "\n",
    "* There are **no null values** in the dataset.\n",
    "\n",
    "* **Booking_ID column is an identifier**. Let's check if each entry of the column is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rH4eaqAYB5gn",
    "outputId": "c5e1f846-db7f-48b0-b845-88d5728e20a2"
   },
   "outputs": [],
   "source": [
    "data.Booking_ID.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHnsORKhB5go"
   },
   "source": [
    "**Observations:**\n",
    "- We can see that **all the entries of this column are unique**. Hence, this column would not add any value to our analysis. \n",
    "- Let's drop this column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALVKTamvB5go"
   },
   "source": [
    "### **Dropping the Booking_ID column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "referenced-architect"
   },
   "outputs": [],
   "source": [
    "data = __________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jj7pIdPHB5go",
    "outputId": "5d8de664-6ff3-441b-f6d3-940613b159ba"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "realistic-mortgage"
   },
   "source": [
    "## **Exploratory Data Analysis and Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seeing-newman"
   },
   "source": [
    "### **Summary Statistics for numerical columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmSrQn_cB5gp",
    "outputId": "a35a36f5-4771-44ac-80a8-55a1b7b6c2a7"
   },
   "outputs": [],
   "source": [
    "# Selecting numerical columns and checking the summary statistics\n",
    "num_cols = data.select_dtypes('number').columns\n",
    "\n",
    "data[num_cols].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "personal-detector"
   },
   "source": [
    "**Observations:_____**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y17IbR98B5gq",
    "outputId": "23225b43-0a25-462c-f756-a6a45cd2eeca"
   },
   "outputs": [],
   "source": [
    "# Checking the rows where the avg_price_per_room is 0\n",
    "data[data[\"avg_price_per_room\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTjEC8ZtB5gq"
   },
   "source": [
    "- In the market segment column, it looks like **many values are complementary**. Let's check the market segment where the room prices are equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bT_DTrwGB5gq",
    "outputId": "876750ee-687e-42e7-fef9-416b26846166"
   },
   "outputs": [],
   "source": [
    "data.loc[data[\"avg_price_per_room\"] == 0, \"market_segment_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyQSfp3GB5gq"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "* It makes sense that most values with room prices equal to 0 are the rooms given as a complimentary service by the hotel.\n",
    "* The rooms booked online might be a part of some promotional campaign done by the hotel. We will not treat these rows as we don't have the data to test this claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7JHq3AYB5gq"
   },
   "source": [
    "### **Checking the distribution and outliers for numerical columns in the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tb6VI7nB5gq",
    "outputId": "e054910f-4318-488f-e7ab-db3d4b698888",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in ['lead_time', 'no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled', 'avg_price_per_room']:\n",
    "    print(col)\n",
    "    \n",
    "    print('Skew :', round(data[col].skew(), 2))\n",
    "    \n",
    "    plt.figure(figsize = (15, 4))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    \n",
    "    data[col].hist(bins = 10, grid = False)\n",
    "    \n",
    "    plt.ylabel('count')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    sns.boxplot(x = data[col])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:__**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqrcelDJB5gr",
    "outputId": "57f685cb-d53c-4748-aa08-ed7846c71953"
   },
   "outputs": [],
   "source": [
    "# Calculating the 25th quantile\n",
    "Q1 = data[\"avg_price_per_room\"].quantile(0.25)\n",
    "\n",
    "# Calculating the 75th quantile\n",
    "Q3 = data[\"avg_price_per_room\"].quantile(0.75)\n",
    "\n",
    "# Calculating IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculating value of upper whisker\n",
    "Upper_Whisker = Q3 + 1.5 * IQR\n",
    "Upper_Whisker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydsOAN5lB5gr"
   },
   "outputs": [],
   "source": [
    "# Assigning the value of upper whisker to outliers\n",
    "data.loc[data[\"avg_price_per_room\"] >= 500, \"avg_price_per_room\"] = Upper_Whisker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r37QH4r0B5gr"
   },
   "source": [
    "**Now, let's check the percentage of each category for categorical variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PTfFp1YB5gr"
   },
   "outputs": [],
   "source": [
    "cat_cols = ['no_of_adults', 'no_of_children', 'no_of_week_nights', 'no_of_weekend_nights', 'required_car_parking_space', \n",
    "        'type_of_meal_plan', 'room_type_reserved', 'arrival_month', 'market_segment_type', 'no_of_special_requests', \n",
    "        'booking_status']\n",
    "\n",
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkEGutHpB5gr"
   },
   "source": [
    "**Observations:________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8tmRu52B5gs"
   },
   "source": [
    "### **Replacing values 9 and 10 for the number of children with 3 and encoding the target variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZhA-gBRB5gs"
   },
   "outputs": [],
   "source": [
    "# Replacing values 9 and 10 with 3 for the column no_of_children\n",
    "data[\"no_of_children\"] = data[\"no_of_children\"].replace([9, 10], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIKkM5AZB5gs"
   },
   "outputs": [],
   "source": [
    "data[\"booking_status\"] = data[\"booking_status\"].apply(lambda x: 1 if x == \"Canceled\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM3q1_vgB5gs"
   },
   "source": [
    "**We are done with univariate analysis and data preprocessing. Let's explore the data a bit more with bivariate analysis.**\n",
    "\n",
    "Let's check the relationship of market segment type with the average price per room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmQYlPNjB5gs",
    "outputId": "acb69ce9-3e77-4a77-ccc0-fa7229077eae"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "sns.boxplot(data = data, x = \"market_segment_type\", y = \"avg_price_per_room\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIfH5ms8B5gs"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "* **Rooms booked online have the highest variations in prices.**\n",
    "* The distribution for offline and corporate room prices are almost similar except for some outliers.\n",
    "* Complementary market segment gets the rooms at very low prices, which makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRN57xD6B5gs"
   },
   "source": [
    "**Let's see how booking status varies across different market segments. Also, how lead time impacts booking status.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mf6BH8DaB5gs",
    "outputId": "089a80f7-5c3e-4588-c373-055ea4802f5d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "sns.countplot(x = 'market_segment_type', hue = 'booking_status', data = data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PajvYk5mB5gs"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "* **Online bookings have the highest number of cancellations.**\n",
    "* Bookings made offline are less prone to cancellations.\n",
    "* Corporate and complementary segment also show very low number of cancellations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFzqw7xuB5gt",
    "outputId": "256317e2-f1d5-4f9a-f1aa-f694afcf6a12"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "sns.boxplot(data = data, x = \"booking_status\", y = \"lead_time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1q1TarrB5gt"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "* There's a big difference in the median value of lead time for bookings that were canceled and bookings that were not canceled. \n",
    "- **The higher the lead time, the higher are the chances of a booking being canceled.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcpKaPfPB5gt"
   },
   "source": [
    "**Now, let's check how the arrival month impacts the booking status.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LS3FXo4PB5gt",
    "outputId": "787b47e4-4be7-4716-cd07-876781da88dd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "sns.countplot(x = 'arrival_month', hue = 'booking_status', data = data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExaW5DftB5gt"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- We observed earlier that the month of October has the highest number of bookings but the above plot shows that **October has the highest number of cancellations** as well.\n",
    "- Bookings made for **December and January are least prone to cancellations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_3tJCx1B5gt"
   },
   "source": [
    "**Repeating guests are the guests who stay in the hotel often and are important to brand equity. Let's see what percentage of repeating guests cancel?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qf40d5loB5gt",
    "outputId": "d31ff368-cd67-4fe4-895f-9bd9920945cf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "sns.countplot(x = 'repeated_guest', hue = 'booking_status', data = data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAUi5ycjB5gt"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "* There are **very few repeat customers but the cancellation among them is very less**. \n",
    "* This is a good indication as repeat customers are important for the hospitality industry as they can help in spreading the word of mouth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arranged-courtesy"
   },
   "source": [
    "**We have explored different combinations of variables. Now, let's see the pairwise correlations between all the variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "official-wyoming",
    "outputId": "81a9c889-9e29-4178-924c-ff99a2b6acab"
   },
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brave-hamilton"
   },
   "source": [
    "**Observations:__**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gJZx-rpB5gu"
   },
   "source": [
    "**Now that we have explored our data, let's prepare it for modeling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUYNF0lFB5gu"
   },
   "source": [
    "## **Preparing the data for modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zj7q8BmEB5gu"
   },
   "source": [
    "- Models cannot take non-numeric inputs. So, we will first create dummy variables for all the categorical variables.\n",
    "- We will then split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHXcm8V5B5gu"
   },
   "outputs": [],
   "source": [
    "# Remove the blanks and complete the below code\n",
    "X = ___________\n",
    "Y = ___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdkQZZe7B5gu"
   },
   "outputs": [],
   "source": [
    "# Creating dummy variables, drop_first = True is used to avoid redundant variables\n",
    "X = __________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNfS-6IKB5gu"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.30, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyTglpNBB5gu"
   },
   "source": [
    "## **Building Classification Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ik4t4tCJB5gu"
   },
   "source": [
    "**Before training the model, let's choose the appropriate model evaluation criterion as per the problem at hand.**\n",
    "\n",
    "### **Model evaluation criterion**\n",
    "\n",
    "**Model can make wrong predictions as:**\n",
    "\n",
    "1. Predicting a customer will not cancel their booking but in reality, the customer cancels their booking.\n",
    "2. Predicting a customer will cancel their booking but in reality, the customer does not cancel their booking. \n",
    "\n",
    "**Which case is more important?** \n",
    "* Both the cases are important as:\n",
    "\n",
    "* If we predict that a booking will not be canceled and the booking gets canceled, then the hotel will lose resources and will have to bear additional costs of unsold rooms. The hotel might also have to bear an additional cost of advertising the room again on different distribution channels.\n",
    "\n",
    "* If we predict that a booking will get canceled and the booking doesn't get canceled, then the hotel might not be able to provide satisfactory services to the customer by assuming that this booking will be canceled. This might damage the brand equity.\n",
    "\n",
    "\n",
    "**How to reduce the losses?**\n",
    "\n",
    "* Hotel would want `F1 Score` to be maximized, greater the F1 score, higher are the chances of minimizing False Negatives and False Positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruled-appointment"
   },
   "source": [
    "**Also, let's create a function to calculate and print the classification report and confusion matrix so that we don't have to rewrite the same code repeatedly for each model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUu1RwEIB5gv"
   },
   "outputs": [],
   "source": [
    "# Function to print classification report and get confusion matrix in a proper format\n",
    "\n",
    "def metrics_score(actual, predicted):\n",
    "    \n",
    "    print(classification_report(actual, predicted))\n",
    "    \n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    \n",
    "    plt.figure(figsize = (8, 5))\n",
    "    \n",
    "    sns.heatmap(cm, annot = True,  fmt = '.2f', xticklabels = ['Not Canceled', 'Canceled'], yticklabels = ['Not Canceled', 'Canceled'])\n",
    "    \n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    plt.xlabel('Predicted')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the decision tree classifier on the training data\n",
    "d_tree =  _________\n",
    "\n",
    "d_tree.__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check the performance on the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the training data\n",
    "y_pred_train1 = _____________\n",
    "\n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading confusion matrix (clockwise):**\n",
    "\n",
    "- **True Positive**: Predicting the customer will not cancel the booking and the customer does not cancel the booking.\n",
    "- **False Negative**: Predicting the customer will cancel the booking but the customer does not cancel the booking.\n",
    "- **True Negative**: Predicting the customer will cancel the booking and the customer cancels the booking.\n",
    "- **False Positive**: Predicting the customer will not cancel the booking but the customer cancels the booking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Let's check the performance on test data to see if the model is overfitting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the testing data\n",
    "y_pred_test1 = ________________\n",
    "\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:_________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try hyperparameter tuning using GridSearchCV to find the optimal max_depth** to reduce overfitting of the model. We can tune some other hyperparameters as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Decision Tree - Hyperparameter Tuning**\n",
    "\n",
    "We will use the class_weight hyperparameter with the value equal to {0: 0.3, 1: 0.7} which is **approximately** the opposite of the imbalance in the original data. \n",
    "\n",
    "**This would tell the model that 1 is the important class here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier \n",
    "d_tree_tuned = DecisionTreeClassifier(random_state = 7, class_weight = {0: 0.3, 1: 0.7})\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {'max_depth': np.arange(2, 10), \n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'min_samples_leaf': [5, 10, 20, 25]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations - f1 score for class 1\n",
    "scorer = metrics.make_scorer(f1_score, pos_label = 1)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(d_tree_tuned, parameters, scoring = scorer, cv = 5)\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the classifier to the best combination of parameters\n",
    "d_tree_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data\n",
    "d_tree_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tuned the model and fit the tuned model on the training data. Now, **let's check the model performance on the training and testing data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the training data\n",
    "y_pred_train2 = ________________\n",
    "\n",
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check the model performance on the testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the testing data\n",
    "y_pred_test2 = _____________\n",
    "\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's visualize the tuned decision tree** and observe the decision rules:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is hard to visualize and interpret the tree with depth = 9, We can reduce the depth to 3 and visualize it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(class_weight = {0: 0.3, 1: 0.7}, max_depth = 3,\n",
    "                       min_samples_leaf = 5, random_state = 7)\n",
    "\n",
    "# Fit the best algorithm to the data\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X.columns)\n",
    "\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "tree.plot_tree(tree_model, feature_names = features, filled = True, fontsize = 9, node_ids = True, class_names = True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfG2Uv44B5gw"
   },
   "source": [
    "**Observations:_____**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's look at the feature importance** of the tuned decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance of features in the tree building\n",
    "\n",
    "print (pd.DataFrame(d_tree_tuned.feature_importances_, columns = [\"Imp\"], index = X_train.columns).sort_values(by = 'Imp', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the feature importance\n",
    "importances = d_tree_tuned.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "\n",
    "plt.barh(range(len(indices)), importances[indices], color = 'violet', align = 'center')\n",
    "\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "\n",
    "plt.xlabel('Relative Importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the random forest tree classifier on the training data\n",
    "rf_estimator = ________________\n",
    "\n",
    "rf_estimator._____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the training data\n",
    "y_pred_train3 = ____________\n",
    "\n",
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check the performance on the testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the testing data\n",
    "y_pred_test3 = _______________\n",
    "\n",
    "_______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see if we can get a better model by tuning the random forest classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try **tuning some of the important hyperparameters of the Random Forest Classifier**. \n",
    "\n",
    "We will **not** tune the `criterion` hyperparameter as we know from hyperparameter tuning for decision trees that `entropy` is a better splitting criterion for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier\n",
    "rf_estimator_tuned = RandomForestClassifier(criterion = \"entropy\", random_state = 7)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {\"n_estimators\": [100, 110, 120],\n",
    "    \"max_depth\": [5, 6, 7],\n",
    "    \"max_features\": [0.8, 0.9, 1]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations - f1 score for class 1\n",
    "scorer = metrics.make_scorer(f1_score, pos_label = 1)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rf_estimator_tuned, parameters, scoring = scorer, cv = 5)\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the classifier to the best combination of parameters\n",
    "rf_estimator_tuned = grid_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the best algorithm to the training data\n",
    "rf_estimator_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the training data\n",
    "y_pred_train4 = rf_estimator_tuned.predict(X_train)\n",
    "\n",
    "metrics_score(y_train, y_pred_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** **GridSearchCV can take a long time to run** depending on the number of hyperparameters and the number of values tried for each hyperparameter. **Therefore, we have reduced the number of values passed to each hyperparameter.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The below code might take some time to run depending on your system's configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier \n",
    "rf_estimator_tuned = RandomForestClassifier(criterion = \"entropy\", random_state = 7)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "parameters = {\"n_estimators\": [110, 120],\n",
    "    \"max_depth\": [6, 7],\n",
    "    \"min_samples_leaf\": [20, 25],\n",
    "    \"max_features\": [0.8, 0.9],\n",
    "    \"max_samples\": [0.9, 1],\n",
    "    \"class_weight\": [\"balanced\",{0: 0.3, 1: 0.7}]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations - f1 score for class 1\n",
    "scorer = metrics.make_scorer(f1_score, pos_label = 1)\n",
    "\n",
    "# Run the grid search on the training data using scorer=scorer and cv=5\n",
    "grid_obj = __________________\n",
    "\n",
    "grid_obj = __________________\n",
    "\n",
    "# Save the best estimator to variable rf_estimator_tuned\n",
    "rf_estimator_tuned = ________________\n",
    "\n",
    "#Fit the best estimator to the training data\n",
    "rf_estimator_tuned.______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check the performance of the tuned model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the training data\n",
    "y_pred_train5 = ______________\n",
    "\n",
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check the model performance on the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking performance on the test data\n",
    "y_pred_test5 = _______________\n",
    "\n",
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:___________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One of the drawbacks of ensemble models is that we lose the ability to obtain an interpretation of the model. We cannot observe the decision rules for random forests the way we did for decision trees. So, let's just check the feature importance of the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_estimator_tuned.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "\n",
    "plt.barh(range(len(indices)), importances[indices], color = 'violet', align = 'center')\n",
    "\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "\n",
    "plt.xlabel('Relative Importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TR7O3da1B5gy"
   },
   "source": [
    "### **Write the conclusion on the key factors that are driving the cancellations and write your recommendations to the business on how they can minimize the number of cancellations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUhaxrR7B5gy"
   },
   "source": [
    "### **Conclusion:**\n",
    "\n",
    "Write your conclusion here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8JXKVowB5gy"
   },
   "source": [
    "### **Recommendations:**\n",
    "\n",
    "Write your recommendations here."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "seeing-newman",
    "Rf8nqbG_B5gp",
    "G7JHq3AYB5gq",
    "3CgPYw46B5gr",
    "Z8tmRu52B5gs",
    "wQyT2bnBB5gu",
    "Ik4t4tCJB5gu",
    "mysterious-sight",
    "6H725rCTB5gv",
    "qYM2U1gEB5gv",
    "5lPCFxqTB5gv",
    "4YW-BC7HB5gw",
    "--3lsaKwB5gx",
    "bKpO2l21B5gx",
    "oLL6b9aoB5gx",
    "MM7qAxAhB5gy",
    "TR7O3da1B5gy",
    "KUhaxrR7B5gy",
    "c8JXKVowB5gy"
   ],
   "name": "Learner Notebook - Project_Classification_ML_updated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
