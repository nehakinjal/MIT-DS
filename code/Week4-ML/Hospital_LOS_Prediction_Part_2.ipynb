{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmmAY9ANJdiZ"
   },
   "source": [
    "# **Hospital Length of Stay (LOS) Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pG7RImq5Jnzy"
   },
   "source": [
    "## **Context:**\n",
    "\n",
    "Hospital management is a vital area that gained a lot of attention during the COVID-19 pandemic. **Inefficient distribution of resources like beds, ventilators might lead to a lot of complications**. However, this can be mitigated by **predicting the length of stay (LOS) of a patient before getting admitted**. Once this is determined, the hospital can plan a suitable treatment, resources, and staff to reduce the LOS and increase the chances of recovery. The rooms and bed can also be planned in accordance with that.\n",
    "\n",
    "**HealthPlus hospital has been incurring a lot of losses in revenue and life due to its inefficient management system.** They have been unsuccessful in allocating pieces of equipment, beds, and hospital staff fairly. **A system that could estimate the length of stay (LOS) of a patient can solve this problem to a great extent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDFFGBh5JuM_"
   },
   "source": [
    "## **Objective:**\n",
    "\n",
    "As a Data Scientist, you have been hired by HealthPlus to analyze the data, find out **what factors affect the LOS the most, and come up with a machine learning model which can predict the LOS of a patient** using the data available during admission and after running a few tests. Also, **bring about useful insights and policies from the data, which can help the hospital to improve their health care infrastructure and revenue.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY6qQyYnn4av"
   },
   "source": [
    "## **Data Dictionary:**\n",
    "\n",
    "The data contains various information recorded during the time of admission of the patient. It only contains **records of patients who were admitted to the hospital.** The detailed data dictionary is given below:\n",
    "\n",
    "\n",
    "* **patientid**: Patient ID\n",
    "* **Age**: Range of age of the patient\n",
    "* **gender**: Gender of the patient\n",
    "* **Type of Admission**: Trauma, emergency or urgent\n",
    "* **Severity of Illness**: Extreme, moderate, or minor\n",
    "* **health_condition**s: Any previous health conditions suffered by the patient\n",
    "* **Visitors with Patient**: The number of patients who accompany the patient\n",
    "* **Insurance**: Does the patient have health insurance or not?\n",
    "* **Admission_Deposit**: The deposit paid by the patient during admission\n",
    "* **Stay (in days)**: The number of days that the patient has stayed in the hospital. This is the **target variable**\n",
    "* **Available Extra Rooms in Hospital**: The number of rooms available during admission\n",
    "* **Department**: The department which will be treating the patient\n",
    "* **Ward_Facility_Code**: The code of the ward facility in which the patient will be admitted\n",
    "* **doctor_name**: The doctor who will be treating the patient\n",
    "* **staff_available**: The number of staff who are not occupied at the moment in the ward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HwCLXEdleNm"
   },
   "source": [
    "## **Approach to solve the problem:**\n",
    "\n",
    "1. Import the necessary libraries\n",
    "2. Read the dataset and get an overview\n",
    "3. Exploratory data analysis - a. Univariate b. Bivariate\n",
    "4. Data preprocessing if any\n",
    "5. Define the performance metric and build ML models\n",
    "6. Checking for assumptions\n",
    "7. Compare models and determine the best one\n",
    "8. Observations and business insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh6pbSWLJ7pT"
   },
   "source": [
    "## **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:13:03.439266Z",
     "start_time": "2023-01-11T12:13:03.423935Z"
    },
    "id": "tu98q-R-KFfP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Removes the limit for the number of displayed columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Sets the limit for the number of displayed rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# To build models for prediction\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor\n",
    "\n",
    "# To encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For tuning the model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# To check model performance\n",
    "from sklearn.metrics import make_scorer,mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:01.434559Z",
     "start_time": "2023-01-11T11:51:00.670898Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "VvautAjCU6Im",
    "outputId": "84ae08b3-71d1-452b-d264-9e26e32ec842"
   },
   "outputs": [],
   "source": [
    "# Read the healthcare dataset file\n",
    "data = pd.read_csv(\"healthcare_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:01.486571Z",
     "start_time": "2023-01-11T11:51:01.435380Z"
    },
    "id": "HAW7LbQGDzc_"
   },
   "outputs": [],
   "source": [
    "# Copying data to another variable to avoid any changes to original data\n",
    "same_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUEuNqtbPVT0"
   },
   "source": [
    "## **Data Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:01.523780Z",
     "start_time": "2023-01-11T11:51:01.489959Z"
    },
    "id": "1WBP3qyFFlAM"
   },
   "outputs": [],
   "source": [
    "# View the first 5 rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:01.556061Z",
     "start_time": "2023-01-11T11:51:01.524957Z"
    },
    "id": "G-JcE75QFv6o"
   },
   "outputs": [],
   "source": [
    "# View the last 5 rows of the dataset\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:01.571371Z",
     "start_time": "2023-01-11T11:51:01.557061Z"
    },
    "id": "oh0JY34cdYHB"
   },
   "outputs": [],
   "source": [
    "# Understand the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKUvaKzkdjUc"
   },
   "source": [
    "- The dataset has **5,00,000 rows and 15 columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:01.729764Z",
     "start_time": "2023-01-11T11:51:01.572372Z"
    },
    "id": "shfF1UM7Ke5E"
   },
   "outputs": [],
   "source": [
    "# Checking the info of the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LQeBs4sPHNK"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "-  Available Extra Rooms in Hospital, staff_available, patientid, Visitors with Patient, Admission_Deposit, and Stay (in days) are of **numeric data type** and the rest of the columns are of **object data type**.\n",
    "- The number of non-null values is the same as the total number of entries in the data, i.e., **there are no null values.**\n",
    "- The column patientid is an identifier for patients in the data. This column will not help with our analysis so we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:01.761620Z",
     "start_time": "2023-01-11T11:51:01.731766Z"
    },
    "id": "z5Xba7tEO9KE"
   },
   "outputs": [],
   "source": [
    "# To view patientid and the number of times they have been admitted to the hospital\n",
    "data['patientid'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pgZWSL-1vS5"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "- **The maximum number of times the same patient admitted to the hospital is 21 and minimum is 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:01.821832Z",
     "start_time": "2023-01-11T11:51:01.763611Z"
    },
    "id": "HM40YACV7O5j"
   },
   "outputs": [],
   "source": [
    "# Dropping patientid from the data as it is an identifier and will not add value to the analysis\n",
    "data=data.drop(columns=[\"patientid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:02.186975Z",
     "start_time": "2023-01-11T11:51:01.824219Z"
    },
    "id": "z73h7AF9r1PM"
   },
   "outputs": [],
   "source": [
    "# Checking for duplicate values in the data\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kp4_mcJjP3LE"
   },
   "source": [
    "**Observation:** \n",
    "- Data contains unique rows. There is no need to remove any rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:02.328801Z",
     "start_time": "2023-01-11T11:51:02.189278Z"
    },
    "id": "QIvXLbuuSuEE"
   },
   "outputs": [],
   "source": [
    "# Checking the descriptive statistics of the columns\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTfliAV--0q5"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "* There are around **3 rooms available in the hospital on average** and there are times when the hospital is full and there are no rooms available (minimum value is 0). The **maximum number of rooms available in the hospital is 24**.\n",
    "* **On average, there are around 5 staff personnel available to treat the new patients** but it can also be zero at times. The maximum number of staff available in the hospital is 10.\n",
    "* **On average, around 3 visitors accompany the patient.** Some patients come on their own (minimum value is zero) and a few cases have 32 visitors. It will be interesting to see if there is any relationship between the number of visitors and the severity of the patient.\n",
    "* **The average admission deposit lies around 4,722 dollars and a minimum of 1,654 dollars is paid on every admission.**\n",
    "* **Patient's stay ranges from 3 to 51 days.** There might be outliers in this variable. The median length of stay is 9 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:02.660600Z",
     "start_time": "2023-01-11T11:51:02.329982Z"
    },
    "id": "wYe3XYCFS1ru"
   },
   "outputs": [],
   "source": [
    "# List of all important categorical variables\n",
    "cat_col = [\"Department\", \"Type of Admission\", 'Severity of Illness', 'gender', 'Insurance', 'health_conditions', 'doctor_name', \"Ward_Facility_Code\", \"Age\"]\n",
    "\n",
    "# Printing the number of occurrences of each unique value in each categorical column\n",
    "for column in cat_col:\n",
    "    print(data[column].value_counts(1))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSIXtFmtgeNJ"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- **The majority of patients (~82%) admit to the hospital with moderate and minor illness**, which is understandable as extreme illness is less frequent than moderate and minor illness. \n",
    "- **Gynecology department gets the most number of patients (~68%)** in the hospital, whereas patients in Surgery department are very few (~1%).\n",
    "- **Ward A and C accommodate the least number of patients (~12%).** These might be wards reserved for patient with extreme illness and patients who need surgery. It would be interesting to see if patients from these wards also stay for longer duration.\n",
    "- **The majority of patients belong to the age group of 21-50 (~75%), and the majority of patients are women (~74%).** The most number of patients in the gynecology department of the hospital can justify this.\n",
    "- Most of the patients admitted to the hospital are the cases of trauma (~62%).\n",
    "- After 'Other' category, **High Blood Pressure and Diabetes are the most common health conditions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTHU4IPogofK"
   },
   "source": [
    "## **Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gU_-9VCyskuV"
   },
   "source": [
    "### **Univariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:02.691027Z",
     "start_time": "2023-01-11T11:51:02.663602Z"
    },
    "id": "3FXeuDBXU3Dv"
   },
   "outputs": [],
   "source": [
    "# Function to plot a boxplot and a histogram along the same scale\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to the show density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows = 2,      # Number of rows of the subplot grid = 2\n",
    "        sharex = True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw = {\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize = figsize,\n",
    "    )                   # Creating the 2 subplots\n",
    "    sns.boxplot(data = data, x = feature, ax = ax_box2, showmeans = True, color = \"violet\"\n",
    "    )                   # Boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data = data, x = feature, kde = kde, ax = ax_hist2, bins = bins, palette = \"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data = data, x = feature, kde = kde, ax = ax_hist2\n",
    "    )                   # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color = \"green\", linestyle = \"--\"\n",
    "    )                   # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color = \"black\", linestyle = \"-\"\n",
    "    )                   # Add median to the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeEmAqhGBlQ3"
   },
   "source": [
    "#### **Length of stay**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:06.621973Z",
     "start_time": "2023-01-11T11:51:02.693952Z"
    },
    "id": "eZavZx-IU47X"
   },
   "outputs": [],
   "source": [
    "histogram_boxplot(data, \"Stay (in days)\", kde = True, bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f59iZeHCE9m"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- **Fewer patients are staying more than 10 days in the hospital and very few stay for more than 40 days**. This might be because the majority of patients are admitted for moderate or minor illnesses. \n",
    "- The peak of the distribution shows that **most of the patients stay for 8-9 days in the hospital.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwYRba3GCmMR"
   },
   "source": [
    "#### **Admission Deposit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:10.261242Z",
     "start_time": "2023-01-11T11:51:06.623923Z"
    },
    "id": "45-b0yudsw8V"
   },
   "outputs": [],
   "source": [
    "histogram_boxplot(data, \"Admission_Deposit\", kde = True, bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iuWUHFtC40E"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "- The **distribution of admission fees is close to normal with outliers on both sides**. Few patients are paying a high amount of admission fees and few patients are paying a low amount of admission fees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnawqWwiDGAN"
   },
   "source": [
    "#### **Visitors with Patients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:15.078344Z",
     "start_time": "2023-01-11T11:51:10.265355Z"
    },
    "id": "zaFuytims4mK"
   },
   "outputs": [],
   "source": [
    "histogram_boxplot(data, \"Visitors with Patient\", kde = True, bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDwBBE2eDOxo"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- The distribution of the number of visitors with the patient is **highly skewed towards the right**.\n",
    "- **2 and 4 are the most common number of visitors with patients.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5PnzTiBuJA5"
   },
   "source": [
    "### **Bivariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:15.495632Z",
     "start_time": "2023-01-11T11:51:15.079640Z"
    },
    "id": "ARmMlB5IO3UQ"
   },
   "outputs": [],
   "source": [
    "# Finding the correlation between various columns of the dataset\n",
    "plt.figure(figsize = (15,7))\n",
    "sns.heatmap(data.corr(), annot = True, vmin = -1, vmax = 1, fmt = \".2f\", cmap = \"Spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXjMP0xgPHoW"
   },
   "source": [
    "**Observations:** \n",
    "- The heatmap shows that there is **no correlation between variables**.\n",
    "- The continuous variables show no correlation with the target variable (Stay (in days)), which indicates that the **categorical variables might be more important for the prediction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:15.529178Z",
     "start_time": "2023-01-11T11:51:15.504262Z"
    },
    "id": "TbM2637QiV0D"
   },
   "outputs": [],
   "source": [
    "# Function to plot stacked bar plots\n",
    "\n",
    "def stacked_barplot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a stacked bar chart\n",
    "\n",
    "    data: dataframe\n",
    "    predictor: independent variable\n",
    "    target: target variable\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins = True).sort_values(\n",
    "        by = sorter, ascending = False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize = \"index\").sort_values(\n",
    "        by = sorter, ascending = False\n",
    "    )\n",
    "    tab.plot(kind = \"bar\", stacked = True, figsize = (count + 1, 5))\n",
    "    plt.legend(\n",
    "        loc = \"lower left\",\n",
    "        frameon = False,\n",
    "    )\n",
    "    plt.legend(loc = \"upper left\", bbox_to_anchor = (1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7g781gtwOV2"
   },
   "source": [
    "**Let's start by checking the distribution of the LOS for the various wards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:21.950365Z",
     "start_time": "2023-01-11T11:51:15.534167Z"
    },
    "id": "z3C3qUsTlIpK"
   },
   "outputs": [],
   "source": [
    "sns.barplot(y = 'Ward_Facility_Code', x = 'Stay (in days)', data = data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ScD8h0FHRxX"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "- The hypothesis we made earlier is correct, i.e., **wards A and C has the patients staying for the longest duration, which implies these wards might be for patients with serious illnesses.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:22.761887Z",
     "start_time": "2023-01-11T11:51:21.950863Z"
    },
    "id": "UH3lFpuU4I6B"
   },
   "outputs": [],
   "source": [
    "stacked_barplot(data, \"Ward_Facility_Code\", \"Department\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26J9ZLFC4WO7"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- **Ward Facility B, D, and F are dedicated only to the gynecology department.**\n",
    "- Wards A, C, and E have patients with all other diseases, and **patients undergoing surgery are admitted to ward A only.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "So2J-eKbxLXE"
   },
   "source": [
    "**Usually, the more severe the illness, the more the LOS, let's check the distribution of severe patients in various wards.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:23.561223Z",
     "start_time": "2023-01-11T11:51:22.761887Z"
    },
    "id": "W-_Kr-34iXUp"
   },
   "outputs": [],
   "source": [
    "stacked_barplot(data, \"Ward_Facility_Code\", \"Severity of Illness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiDH49bWIAJF"
   },
   "source": [
    "**Observations:**\n",
    "\n",
    "- **Ward A has the highest number of extreme cases.** We observed earlier that ward A has the longest length of stay in the hospital as well. It might require more staff and resources as compared to other wards.\n",
    "- **Ward F has the highest number of minor cases and Ward E has the highest number of moderate cases.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4pmLBDiyJ4c"
   },
   "source": [
    "**Age can also be an important factor to find the length of stay. Let's check the same.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:30.484892Z",
     "start_time": "2023-01-11T11:51:23.561223Z"
    },
    "id": "FmSuZ_18n7Ch"
   },
   "outputs": [],
   "source": [
    "sns.barplot(y = 'Age', x = 'Stay (in days)', data = data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsYpNHK2It36"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "- **Patients aged between 1-10 and 51-100 tend to stay the most number of days in the hospital.** This might be because the majority of the patients between the 21-50 age group get admitted to the gynecology department and patients in age groups 1-10 and 5-100 might get admitted due to some serious illness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's look at the doctors, their department names, and the total number of patients they have treated.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:30.594673Z",
     "start_time": "2023-01-11T11:51:30.484892Z"
    }
   },
   "outputs": [],
   "source": [
    "data.groupby(['doctor_name'])['Department'].agg(Department_Name='unique',Patients_Treated='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- The hospital employs a total of 9 doctors. Four of the doctors work in the department of gynecology, which sees the most patients.\n",
    "- The majority of patients that attended the hospital were treated by Dr. Sarah and Olivia.\n",
    "- Two doctors are working in the surgical department (Dr. Isaac and Dr. Simon), while Dr. Sam works in the radiotherapy department.\n",
    "- The only two doctors who work in several departments are Dr. John and Dr. Mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTjAF7lA2A9v"
   },
   "source": [
    "## **Data Preparation for Model Building**\n",
    "\n",
    "- Before we proceed to build a model, we'll have to encode categorical features.\n",
    "- Separate the independent variables and dependent Variables.\n",
    "- We'll split the data into train and test to be able to evaluate the model that we train on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:31.210131Z",
     "start_time": "2023-01-11T11:51:30.596297Z"
    },
    "id": "R9sae8pN9cGT"
   },
   "outputs": [],
   "source": [
    "# Creating dummy variables for the categorical columns\n",
    "# drop_first=True is used to avoid redundant variables\n",
    "data = pd.get_dummies(\n",
    "    data,\n",
    "    columns = data.select_dtypes(include = [\"object\", \"category\"]).columns.tolist(),\n",
    "    drop_first = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:31.273795Z",
     "start_time": "2023-01-11T11:51:31.212330Z"
    },
    "id": "Ri-VtxAj9fdT"
   },
   "outputs": [],
   "source": [
    "# Check the data after handling categorical data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:31.348221Z",
     "start_time": "2023-01-11T11:51:31.273795Z"
    },
    "id": "CpnezOEgjQY7"
   },
   "outputs": [],
   "source": [
    "# Separating independent variables and the target variable\n",
    "x = data.drop('Stay (in days)',axis=1)\n",
    "\n",
    "y = data['Stay (in days)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:31.565705Z",
     "start_time": "2023-01-11T11:51:31.350232Z"
    },
    "id": "KTg4-p8-9EO7"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:31.597640Z",
     "start_time": "2023-01-11T11:51:31.565895Z"
    },
    "id": "rEG6Rs2wjVrO"
   },
   "outputs": [],
   "source": [
    "# Checking the shape of the train and test data\n",
    "print(\"Shape of Training set : \", x_train.shape)\n",
    "print(\"Shape of test set : \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwDclxhA8ply"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SH1_ef6jSVcD"
   },
   "source": [
    "* We will be using different metrics functions defined in sklearn like RMSE, MAE, 𝑅2, Adjusted 𝑅2, and MAPE for regression models evaluation. We will define a function to calculate these metric.\n",
    "* The mean absolute percentage error (MAPE) measures the accuracy of predictions as a percentage, and can be calculated as the average of absolute percentage error for all data points. The absolute percentage error is defined as predicted value minus actual values divided by actual values. It works best if there are no extreme values in the data and none of the actual values are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:31.613284Z",
     "start_time": "2023-01-11T11:51:31.597640Z"
    },
    "id": "v4s83hAM9I8X"
   },
   "outputs": [],
   "source": [
    "# Function to compute adjusted R-squared\n",
    "def adj_r2_score(predictors, targets, predictions):\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    n = predictors.shape[0]\n",
    "    k = predictors.shape[1]\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "\n",
    "\n",
    "# Function to compute MAPE\n",
    "def mape_score(targets, predictions):\n",
    "    return np.mean(np.abs(targets - predictions) / targets) * 100\n",
    "\n",
    "\n",
    "# Function to compute different metrics to check performance of a regression model\n",
    "def model_performance_regression(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check regression model performance\n",
    "\n",
    "    model: regressor\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    pred = model.predict(predictors)                  # Predict using the independent variables\n",
    "    r2 = r2_score(target, pred)                       # To compute R-squared\n",
    "    adjr2 = adj_r2_score(predictors, target, pred)    # To compute adjusted R-squared\n",
    "    rmse = np.sqrt(mean_squared_error(target, pred))  # To compute RMSE\n",
    "    mae = mean_absolute_error(target, pred)           # To compute MAE\n",
    "    mape = mape_score(target, pred)                   # To compute MAPE\n",
    "\n",
    "    # Creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae,\n",
    "            \"R-squared\": r2,\n",
    "            \"Adj. R-squared\": adjr2,\n",
    "            \"MAPE\": mape,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:32.716021Z",
     "start_time": "2023-01-11T11:51:31.615470Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:32.855238Z",
     "start_time": "2023-01-11T11:51:32.716021Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking performance on the training data\n",
    "linear_reg = model_performance_regression(model, x_train, y_train)\n",
    "linear_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:32.899827Z",
     "start_time": "2023-01-11T11:51:32.855238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking performance on the testing data\n",
    "linear_reg_test = model_performance_regression(model, x_test, y_test)\n",
    "linear_reg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- **The Root Mean Squared Error** and the **adjusted $R^2$** of train and test data are **very close**, indicating that **our model is not overfitting** to the training data.\n",
    "\n",
    "- The adjusted $R^2$ of ~0.84 implies that the independent variables are able to explain ~84% variance in the target variable.\n",
    "\n",
    "- Mean Absolute Error (MAE) indicates that the current model can predict LOS of patients within **mean error of 2.15 days** on the test data.\n",
    "\n",
    "- The units of both RMSE and MAE are the same, i.e., days in this case. But RMSE is greater than MAE because it penalizes the outliers more.\n",
    "\n",
    "- **Mean Absolute Percentage Error is ~19%** on the test data, indicating that the average difference between the predicted value and the actual value is ~19%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization** is a fundamental concept in machine learning. It is a method of preventing the model from **overfitting** by adding additional information to it.\n",
    "\n",
    "The machine learning model may perform well with training data but not with test data. It means that when dealing with unseen data, the model cannot anticipate the result since it introduces noise into the output, and so the model is termed **overfit**. A **regularization** technique can be used to solve this problem.\n",
    "\n",
    "By lowering the magnitude of the variables, this technique allows for the preservation of all variables or features in the model. As a result, it maintains accuracy as well as model generalization.\n",
    "\n",
    "Its primary function is to regularize or lower the coefficient of features towards zero. In other words, \"the regularization strategy reduces the magnitude of the features while maintaining the same number of features.\"\n",
    "\n",
    "Regularization is accomplished by introducing a penalty or complexity term into the complex model.\n",
    "\n",
    "Regularization procedures are classified into two types, which are listed below:\n",
    "\n",
    "\n",
    "- **Ridge Regression**\n",
    "- **Lasso Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge regression** is a sort of linear regression in which a **small amount of bias** is introduced to improve long-term predictions.\n",
    "\n",
    "- Ridge regression is a regularization technique that is **used to reduce model complexity**. It's also known as **$L_2$ regularization**.\n",
    "\n",
    "- The penalty term is added to the cost function in this technique. The amount of bias introduced into the model is referred to as the **Ridge Regression penalty**.\n",
    "\n",
    "- We may compute it by multiplying the squared weight of each individual feature by the alpha.\n",
    "\n",
    "- In general, Ridge Regression calculates the equation's parameters:\n",
    "\n",
    "$$\\Large\\ \\hat{y}\\  = slope \\times X + y\\ intercept$$\n",
    "\n",
    "By minimizing the:\n",
    "\n",
    "$$\\Large\\ the\\ sum\\ of\\ squared\\ residuals + \\alpha \\times slope^{2} $$ \n",
    "\n",
    "- As we can see from the above equation, if the values of $\\alpha$ tend to **zero**, the equation becomes the linear regression model's cost function. As a result, for the **minimum value of $\\alpha$**, the model will be similar to the linear regression model.\n",
    "\n",
    "- Because a general linear or polynomial regression will fail if the independent variables are highly collinear, Ridge regression can be utilized to tackle such situations.\n",
    "- When we have more parameters than samples, it is easier to solve problems using Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:33.219937Z",
     "start_time": "2023-01-11T11:51:32.901829Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_model = Ridge() #creating Ridge Regression model\n",
    "ridge_model.fit(x_train, y_train) # Fitting the data into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:51:33.283072Z",
     "start_time": "2023-01-11T11:51:33.222815Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_reg = model_performance_regression(ridge_model, x_test, y_test) #getting performance metrics on test data\n",
    "ridge_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- The performance metrics are showing almost similar results as compared to the Least Squares method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression with optimized $\\large\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:52:17.270194Z",
     "start_time": "2023-01-11T11:51:33.283072Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=10, shuffle=True, random_state=1) \n",
    "params = {'alpha':[0.001, 0.01, 0.1, 0.2, 0.5, 0.9, 1, 5,10,20]} \n",
    "model = Ridge()\n",
    "model_cv = GridSearchCV(estimator=model, param_grid=params, scoring='r2', cv=folds, return_train_score=True)\n",
    "model_cv.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:52:17.295800Z",
     "start_time": "2023-01-11T11:52:17.270296Z"
    }
   },
   "outputs": [],
   "source": [
    "model_cv.best_params_ #getting optimised parameters for alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:52:17.539986Z",
     "start_time": "2023-01-11T11:52:17.295800Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_model_tuned = Ridge(alpha=0.1) ##creating Tuned Ridge Regression model using optimised alpha value\n",
    "ridge_model_tuned.fit(x_train, y_train) # Fitting the data into the tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:52:17.584732Z",
     "start_time": "2023-01-11T11:52:17.539986Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_reg_tuned = model_performance_regression(ridge_model_tuned, x_test, y_test) #getting performance metrics on test data\n",
    "ridge_reg_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- After applying the Grid SearchCV, the optimized value of alpha results out to be 0.1.\n",
    "- It can be observed that after tuning the parameters of Ridge Regression, the performance parameters does not change implying that Ridge Regression does not help in improving the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso regression** is another regularisation technique for reducing model complexity. It is an abbreviation for **Least Absolute and Selection Operator.**\n",
    "\n",
    "- It is identical to Ridge Regression except that the **penalty term only contains absolute weights** rather than a square of weights.\n",
    "\n",
    "\n",
    "- Because it uses absolute data, it **can decrease the slope to zero**, whereas **Ridge Regression can only get close to zero**.\n",
    "\n",
    "- It is also known as **$L_1$ regularisation**.\n",
    "\n",
    "Fundamentally, Lasso Regression calculates the equation's parameters:\n",
    "\n",
    "$$\\Large\\ \\hat{y}\\  = slope \\times X + y\\ intercept$$\n",
    "\n",
    "By minimizing the:\n",
    "\n",
    "$$\\Large\\ the\\ sum\\ of\\ squared\\ residuals + \\alpha \\times |slope| $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:52:17.970069Z",
     "start_time": "2023-01-11T11:52:17.586418Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_model = Lasso()\n",
    "lasso_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:52:18.040549Z",
     "start_time": "2023-01-11T11:52:17.970069Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_reg = model_performance_regression(lasso_model, x_test, y_test)\n",
    "lasso_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- After fitting the data into Lasso Regression Model with default value of alpha (=1), the performance metrics are showing poor results as compared to Least Squares method and Ridge Regression.\n",
    "- We can tune the alpha to get the optimized value similar to Ridge Regression using Grid SearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression with optimized $\\large\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:55:50.071033Z",
     "start_time": "2023-01-11T11:52:18.040549Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "params = {'alpha':[0.001, 0.01, 0.1, 0.2, 0.5, 0.9, 1, 5,10,20]}\n",
    "model = Lasso()\n",
    "model_cv = GridSearchCV(estimator=model, param_grid=params, scoring='r2', cv=folds, return_train_score=True)\n",
    "model_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:55:50.089177Z",
     "start_time": "2023-01-11T11:55:50.073780Z"
    }
   },
   "outputs": [],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:56:01.503013Z",
     "start_time": "2023-01-11T11:55:50.091695Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_model_tuned = Lasso(alpha=0.001)\n",
    "lasso_model_tuned.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T11:56:01.567344Z",
     "start_time": "2023-01-11T11:56:01.503013Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_reg_tuned = model_performance_regression(lasso_model_tuned, x_test, y_test)\n",
    "lasso_reg_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "- After applying the Grid SearchCV, the optimized value of alpha results out to be 0.001.\n",
    "- The performance metrics are showing similar results as compared to Least Squares method and Ridge Regression, implying that after adding the penalty, the model does not improve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "|\\theta_i|}+ {\\alpha \\cdot L_1Ratio} \\sum_{i=1}^m{{|\\theta_i|": "<p><strong>SyntaxError</strong>: invalid syntax (Temp/ipykernel_18476/2473224346.py, line 1)</p>\n"
    }
   },
   "source": [
    "**Elastic Net** is a regularized regression model that combines $L_1$ and $L_2$ penalties, i.e., **lasso** and **ridge** regression. As a result, it performs a more efficient smoothing process.\n",
    "\n",
    "- The elastic net includes the **penalty of lasso regression**, and **when used in isolation, it becomes the ridge regression**. \n",
    "- In the procedure of regularization with an elastic net, **first, the coefficient of ridge regression is determined**. \n",
    "- After this, a **lasso algorithm is performed on the ridge regression coefficient to shrink the coefficient**.\n",
    "- It has two parameters to be set, $\\large\\alpha_1$ and $\\large\\alpha_2$ where $\\large\\alpha_1$ controls the $L_1$ penalty and $\\large\\alpha_2$ controls the $L_2$ penalty.\n",
    "\n",
    "Instead of utilising two $\\large\\alpha$-parameters, we can use simply one $\\large\\alpha$ and one $L_1$-ratio-parameter, which sets the proportion of our $L_1$ penalty in relation to $\\large\\alpha$. If $\\large\\alpha = 1$ and $L_1$-ratio = 0.3, our $L_1$ penalty is multiplied by 0.3, and our $L_2$ penalty is multiplied by $1 - L_1-ratio = 0.7$.\n",
    "\n",
    "$$\\large{ElasticNetMSE = MSE(y,y_{pred}) + {\\alpha \\cdot (1 - L_1Ratio)} \\sum_{i=1}^m{{|\\theta_i|}+ {\\alpha \\cdot L_1Ratio} \\sum_{i=1}^m{{|\\theta_i|}}}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:13:12.828342Z",
     "start_time": "2023-01-11T12:13:12.231778Z"
    }
   },
   "outputs": [],
   "source": [
    "elasticnet_model = ElasticNet()\n",
    "elasticnet_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:13:12.891319Z",
     "start_time": "2023-01-11T12:13:12.831374Z"
    }
   },
   "outputs": [],
   "source": [
    "elasticnet_reg = model_performance_regression(elasticnet_model, x_test, y_test)\n",
    "elasticnet_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- After fitting the data into Elastic Net Model with default value of alpha (=1) and l1_ratio, the performance metrics are showing poor results as compared to Least Squares method and Ridge Regression.\n",
    "- We can tune the alpha to get the optimized value similar to Ridge Regression using Grid SearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regression with optimized $\\alpha$ and $L_1-ratio$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:29.632373Z",
     "start_time": "2023-01-11T12:13:12.893052Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "params = {'alpha':[0.001, 0.01, 0.1, 0.2, 0.5, 0.9],\n",
    "         'l1_ratio': [0.001, 0.01, 0.02, 0.03, 0.04, 0.05]}\n",
    "model = ElasticNet()\n",
    "model_cv = GridSearchCV(estimator=model, param_grid=params, scoring='r2', cv=folds, return_train_score=True)\n",
    "model_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:29.678296Z",
     "start_time": "2023-01-11T12:47:29.644234Z"
    }
   },
   "outputs": [],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.371428Z",
     "start_time": "2023-01-11T12:47:29.681888Z"
    }
   },
   "outputs": [],
   "source": [
    "elasticnet_model_tuned = ElasticNet(alpha=0.001, l1_ratio=0.05)\n",
    "elasticnet_model_tuned.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.463265Z",
     "start_time": "2023-01-11T12:47:54.374428Z"
    }
   },
   "outputs": [],
   "source": [
    "elasticnet_reg_tuned = model_performance_regression(elasticnet_model_tuned, x_test, y_test)\n",
    "elasticnet_reg_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "- After applying the Grid SearchCV, the optimized value of alpha results out to be 0.001, and l1_ratio = 0.05.\n",
    "- The performance metrics are showing almost similar results as compared to Least Squares method, Ridge Regression and Lasso Regression, implying that after tuning the Elastic Net, the model does not improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:48:24.560408Z",
     "start_time": "2023-01-11T12:48:24.535726Z"
    }
   },
   "outputs": [],
   "source": [
    "models= pd.concat([linear_reg_test,ridge_reg,ridge_reg_tuned,lasso_reg,lasso_reg_tuned,elasticnet_reg,\n",
    "                   elasticnet_reg_tuned], axis=0) #combining all models into a single dataframe\n",
    "models['Models'] = ['Least Squares', 'Ridge Regression', 'Ridge Regression Tuned', 'Lasso Regression',\n",
    "                                      'Lasso Regression Tuned', 'Elastic Net Regression',\n",
    "                    'Elastic Net Regression Tuned'] #adding names of the models as a column to the dataframe\n",
    "models = models.iloc[:,[5, 0,1,2,3,4]] #ordering names of the models as the first column\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- As per the above result, the **Least Squares Method** is giving the best results as compared to other models. \n",
    "- Regularization technique does not offer any significant improvement to the performance metrics.\n",
    "- So, we will apply some **Non Linear models** to check if the model performance improves or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Feature Selection using SequentialFeatureSelector\n",
    "\n",
    "We will see how to use **SequentialFeatureSelector** to select a subset of key features using forward feature selection. It is a greedy search algorithm that is used to **reduce an initial d-dimensional feature space to a k-dimensional feature subspace where k < d**. It is useful to automatically select a subset of the most relevant featuresthat are most relevant to the problem.\n",
    "\n",
    "**Why should we do feature selection?**\n",
    "\n",
    "- Reduces dimensionality\n",
    "- Discards deceptive features; Deceptive features appear to aid learning on the training set but impair generalization\n",
    "- Speeds training/testing\n",
    "\n",
    "\n",
    "**How does forward feature selection work?**\n",
    "\n",
    "* It starts with an empty model and adds variables one by one.\n",
    "* In each forward step, you add the one variable that gives the highest improvement to your model.\n",
    "\n",
    "\n",
    "We will use forward feature selection on all the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SFS.png](SFS.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:48:43.712813Z",
     "start_time": "2023-01-11T12:48:40.150180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Installing mlxtend library. You need to run the below code only once if mlxtend library is not previously installed.\n",
    "\n",
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:49:09.803945Z",
     "start_time": "2023-01-11T12:49:09.756838Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Sequential Feature Selector\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters to pass in SequentialFeatureSelector:**\n",
    "\n",
    "- **estimator:** scikit-learn classifier or regressor.\n",
    "\n",
    "- **k_features:** int or tuple or str (default: 1). \n",
    "\n",
    "    - The number of features to choose, where k features equals the entire feature collection, can be specified as an integer.\n",
    "    - The SFS will consider returning any feature combination between min and max that scored highest in cross-validation if a tuple containing a min and max value is provided. For example, instead of a set amount of characteristics k, the tuple (1, 4) will return any combination of 1 to 4 features.\n",
    "    - A string argument such as \"best\" or \"parsimonious\". If you choose \"best,\" the feature selector will provide the feature subset with the best cross-validation performance. If the input \"parsimonious\" is provided, the smallest feature subset that is within one standard error of the cross-validation performance will be chosen.\n",
    "    \n",
    "- **forward:** bool (default: True). Forward selection if True, backward selection otherwise.\n",
    "\n",
    "- **floating:** bool (default: False). Adds a conditional exclusion/inclusion if True:\n",
    "\n",
    "    - Sequential floating forward selection (SFFS) starts from the empty set.\n",
    "    - After\teach forward step, it performs backward\tsteps as long as the objective function increases.\n",
    "    - Once it stops increasing, the forward selection is continued.\n",
    "\n",
    "- **verbose:** int (default: 0), level of verbosity to use in logging. If 0 then no output, if 1then the number of features in the current set, and if 2 then detailed logging including timestamp and cv scores at each step.\n",
    "\n",
    "- **scoring:** str, callable, or None (default: None). If None (default), uses 'accuracy' for sklearn classifiers and 'r2' for sklearn regressors.\n",
    "\n",
    "- **cv:** int (default: 5). Integer or iterable yielding train, test splits. If cv is an integer and estimator is a classifier (or y consists of integer class labels) stratified k-fold. Otherwise, regular k-fold cross-validation is performed. No cross-validation if cv is None, False, or 0.\n",
    "\n",
    "- **n_jobs:** int (default: 1). The number of CPUs to use for evaluating different feature subsets in parallel. -1 means 'all CPUs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T13:57:42.309908Z",
     "start_time": "2023-01-11T12:49:12.606730Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the model to pass to SFS\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Forward Feature Selection\n",
    "sfs = SFS(\n",
    "    reg,\n",
    "    k_features=x_train.shape[1],\n",
    "    forward=True, \n",
    "    floating=False,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1,  \n",
    "    verbose=2,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "# Perform SFS\n",
    "sfs = sfs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the the model performance with addition of each feature. We will use the **plot_sequential_feature_selection** function for this. It has the following parameters:\n",
    "\n",
    "- **metric_dict:** mlxtend.SequentialFeatureSelector.get_metric_dict() object, which is a dictionary with items where each dictionary value is a list with the number of iterations (number of feature subsets) as its length. The **dictionary keys** corresponding to these lists are as follows:\n",
    "    - 'feature_idx': tuple of the indices of the feature subset \n",
    "    - 'cv_scores': list with individual CV scores \n",
    "    - 'avg_score': of CV average scores\n",
    "    - 'feature_names': Name of features in the subset\n",
    "    - 'ci_bound': confidence interval bound of the CV score average\n",
    "    - 'std_dev': standard deviation of the CV score average \n",
    "    - 'std_err': standard error of the CV score average \n",
    "\n",
    "- **figsize:** tuple (default: None). Height and width of the figure.\n",
    "\n",
    "- **kind:** str (default: \"std_dev\"). The kind of error bar or confidence interval in {'std_dev', 'std_err', 'ci', None}.\n",
    "\n",
    "- **color:** str (default: \"blue\"). Color of the lineplot (accepts any matplotlib color name).\n",
    "\n",
    "- **bcolor:** str (default: \"steelblue\"). Color of the error bars / confidence intervals (accepts any matplotlib color name).\n",
    "\n",
    "- **marker:** str (default: \"o\"). Marker of the line plot (accepts any matplotlib marker name).\n",
    "\n",
    "- **alpha:** float in [0, 1] (default: 0.2). Transparency of the error bars / confidence intervals.\n",
    "\n",
    "- **ylabel:** str (default: \"Performance\"). Y-axis label.\n",
    "\n",
    "- **confidence_interval:** float (default: 0.95). Confidence level if kind='ci'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.602855Z",
     "start_time": "2023-01-11T12:47:54.602855Z"
    }
   },
   "outputs": [],
   "source": [
    "sfs.get_metric_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.604581Z",
     "start_time": "2023-01-11T12:47:54.604581Z"
    }
   },
   "outputs": [],
   "source": [
    "# To plot the performance of the model with addition of each feature\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "fig1 = plot_sfs(sfs.get_metric_dict(), kind=\"std_err\", figsize=(15, 5))\n",
    "plt.title(\"Sequential Forward Selection\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.606411Z",
     "start_time": "2023-01-11T12:47:54.606411Z"
    }
   },
   "outputs": [],
   "source": [
    "sfs.get_metric_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** \n",
    "\n",
    "- We can observe that the performance increases till the 8th feature and then becomes constant.\n",
    "- The decision to choose the *k_features* now depends on the $R^2$ vs the complexity of the model.\n",
    "    - With 8 features, we are getting an $R^2$ of 0.840.\n",
    "    - With 20 features, we are getting an $R^2$ of 0.844.\n",
    "    - With 42 features, we are getting an $R^2$ of 0.843.\n",
    "- The increase in $R^2$ is not very significant as we are getting approximately the same values with a less complex model.\n",
    "- So we'll use 8 features only to build the Linear Regression model, but you can experiment by taking a different number.\n",
    "- Number of features chosen can also depend on the business context and use case of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the Sequential Feature Selector again to find the best 8 features for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.608157Z",
     "start_time": "2023-01-11T12:47:54.607886Z"
    }
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "\n",
    "# Forward feature selection with 8 features\n",
    "sfs = SFS(\n",
    "    reg,\n",
    "    k_features=8,\n",
    "    forward=True,\n",
    "    floating=False,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "# Perform SFFS\n",
    "sfs = sfs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.611887Z",
     "start_time": "2023-01-11T12:47:54.611887Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting the features which are important for the model\n",
    "feat_cols = list(sfs.k_feature_idx_)\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.613289Z",
     "start_time": "2023-01-11T12:47:54.613289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the names of the important features\n",
    "x_train.columns[feat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, we will fit the Linear Regression model using these 8 features only.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.615034Z",
     "start_time": "2023-01-11T12:47:54.615034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the new x_train data\n",
    "x_train_final = x_train[x_train.columns[feat_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.616524Z",
     "start_time": "2023-01-11T12:47:54.616524Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the new x_test data\n",
    "x_test_final = x_test[x_train_final.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.617523Z",
     "start_time": "2023-01-11T12:47:54.617523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting Linear Regression model on the new training data\n",
    "lin_reg_model2 = LinearRegression()\n",
    "lin_reg_model2.fit(x_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.619032Z",
     "start_time": "2023-01-11T12:47:54.619032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking model performance on the training data\n",
    "lin_reg_model2_train_perf = model_performance_regression(lin_reg_model2, x_train_final, y_train)\n",
    "lin_reg_model2_train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.620092Z",
     "start_time": "2023-01-11T12:47:54.620092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking model performance on the testing data\n",
    "lin_reg_model2_test_perf = model_performance_regression(lin_reg_model2, x_test_final, y_test)\n",
    "lin_reg_model2_test_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- The performance looks approximately the same as the previous model with all the variables.\n",
    "- Let's compare the two models we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.621102Z",
     "start_time": "2023-01-11T12:47:54.621102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training performance comparison\n",
    "\n",
    "models_train_comp_df = pd.concat(\n",
    "    [linear_reg.T, lin_reg_model2_train_perf.T], axis=1,\n",
    ")\n",
    "\n",
    "models_train_comp_df.columns = [\n",
    "    \"Linear Regression sklearn\",\n",
    "    \"Linear Regression sklearn (SFS features)\",\n",
    "]\n",
    "\n",
    "print(\"Training performance comparison:\")\n",
    "models_train_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T12:47:54.623103Z",
     "start_time": "2023-01-11T12:47:54.623103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing performance comparison\n",
    "\n",
    "models_test_comp_df = pd.concat(\n",
    "    [linear_reg_test.T, lin_reg_model2_test_perf.T], axis=1,\n",
    ")\n",
    "\n",
    "models_test_comp_df.columns = [\n",
    "    \"Linear Regression sklearn\",\n",
    "    \"Linear Regression sklearn (SFS features)\",\n",
    "]\n",
    "\n",
    "print(\"Test performance comparison:\")\n",
    "models_test_comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The new model (**lin_reg_model2**) uses 8 features in comparison to 42 features for the previous model (**linear_reg**), i.e., the number of features has reduced by ~81%.\n",
    "* The performance of the new model, however, is very close to our previous model.\n",
    "* Depending upon time sensitivity and storage restrictions, we can choose between the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have explored building a Linear Regression model for this problem statement of predicting the likely length of stay of a patient for a hospital visit, and we've also identifies the most important features for the model, and trained the model using only those features, without compromising the model performance by much.\n",
    "\n",
    "- However, being a linear model, it is more interpretable than a model with high predictive power. The performance metrics of our attempt at prediction can be improved with more complex and non-linear models.\n",
    "\n",
    "- In the coming section, we will explore building models on more complex regularized versions of Linear Regression, and also get into non-linear tree-based regression models, to see if we can improve on the model's predictive performance."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
